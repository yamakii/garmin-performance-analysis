"""
Integration tests for report generation.

Tests complete workflow from DuckDB to final report.
"""

from pathlib import Path

import pytest

from tools.reporting.report_generator_worker import ReportGeneratorWorker


@pytest.fixture
def test_db(tmp_path):
    """Create test database with production schema."""
    import duckdb

    db_path = tmp_path / "test.duckdb"
    conn = duckdb.connect(str(db_path))

    # Create activities table with complete production schema
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS activities (
            activity_id BIGINT PRIMARY KEY,
            date DATE,
            activity_name VARCHAR,
            location_name VARCHAR,
            total_distance_km DOUBLE,
            total_time_seconds DOUBLE,
            avg_pace_seconds_per_km DOUBLE,
            avg_heart_rate INTEGER,
            avg_cadence DOUBLE,
            avg_power DOUBLE,
            weight_kg DOUBLE,
            external_temp_c DOUBLE,
            humidity INTEGER,
            wind_speed_ms DOUBLE,
            gear_name VARCHAR,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # Create form_efficiency table
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS form_efficiency (
            activity_id BIGINT PRIMARY KEY,
            gct_average DOUBLE,
            gct_std DOUBLE,
            gct_rating VARCHAR,
            vo_average DOUBLE,
            vo_std DOUBLE,
            vo_rating VARCHAR,
            vr_average DOUBLE,
            vr_std DOUBLE,
            vr_rating VARCHAR,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # Create performance_trends table
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS performance_trends (
            activity_id BIGINT PRIMARY KEY,
            pace_consistency DOUBLE,
            hr_drift_percentage DOUBLE,
            cadence_consistency VARCHAR,
            fatigue_pattern VARCHAR,
            warmup_avg_pace_seconds_per_km DOUBLE,
            warmup_avg_hr DOUBLE,
            main_avg_pace_seconds_per_km DOUBLE,
            main_avg_hr DOUBLE,
            finish_avg_pace_seconds_per_km DOUBLE,
            finish_avg_hr DOUBLE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # Create hr_efficiency table
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS hr_efficiency (
            activity_id BIGINT PRIMARY KEY,
            training_type VARCHAR,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # Create section_analyses table
    conn.execute(
        """
        CREATE SEQUENCE IF NOT EXISTS section_analyses_seq START 1;
        CREATE TABLE IF NOT EXISTS section_analyses (
            analysis_id INTEGER PRIMARY KEY DEFAULT nextval('section_analyses_seq'),
            activity_id BIGINT NOT NULL,
            activity_date DATE NOT NULL,
            section_type VARCHAR NOT NULL,
            analysis_data VARCHAR,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            agent_name VARCHAR,
            agent_version VARCHAR
        )
    """
    )

    conn.close()
    return str(db_path)


@pytest.fixture
def test_activity_data():
    """Test activity data."""
    return {
        "activity_id": 12345,
        "activity_date": "2025-09-22",
        "activity_name": "Morning Run",
        "distance_km": 5.0,
        "duration_seconds": 1800,
        "avg_pace_seconds_per_km": 360,
        "avg_heart_rate": 155,
        "avg_cadence": 168,
        "avg_power": 250,
    }


@pytest.fixture
def test_section_analyses():
    """Test section analyses data."""
    return {
        "efficiency": {
            "metadata": {
                "activity_id": "12345",
                "date": "2025-09-22",
                "analyst": "efficiency-section-analyst",
                "version": "1.0",
            },
            "efficiency": {
                "form_efficiency": "GCT: 262ms (â˜…â˜…â˜…â˜†â˜†), VO: 7.2cm (â˜…â˜…â˜…â˜…â˜…)",
                "hr_efficiency": "Zone 1å„ªä½ (63.5%), aerobic_baseå‹",
                "evaluation": "å„ªç§€ãªæ¥åœ°æ™‚é–“ã€åŠ¹ç‡çš„ãªåœ°é¢ååŠ›åˆ©ç”¨",
            },
        },
        "environment": {
            "metadata": {
                "activity_id": "12345",
                "date": "2025-09-22",
                "analyst": "environment-section-analyst",
                "version": "1.0",
            },
            "environmental": {
                "weather_conditions": "æ°—æ¸©18.0Â°Cã€å¿«é©ãªæ¡ä»¶",
                "terrain_impact": "å¹³å¦ã‚³ãƒ¼ã‚¹ (æ¨™é«˜å¤‰åŒ–+2m/-2m)",
                "gear": {
                    "shoes": "Nike Vaporfly Next% 2 (èµ°è¡Œè·é›¢: 245km)",
                    "notes": "ç†æƒ³çš„ãªã‚·ãƒ¥ãƒ¼ã‚ºé¸æŠ",
                },
                "evaluation": "ç†æƒ³çš„ãªç’°å¢ƒæ¡ä»¶ã€é©åˆ‡ãªæ©Ÿæé¸æŠ",
            },
        },
        "phase": {
            "metadata": {
                "activity_id": "12345",
                "date": "2025-09-22",
                "analyst": "phase-section-analyst",
                "version": "1.0",
            },
            "warmup_evaluation": "é©åˆ‡ãªã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—",
            "main_evaluation": "ä¸€è²«ã—ãŸãƒšãƒ¼ã‚¹ç¶­æŒ",
            "finish_evaluation": "é©åˆ‡ãªãƒšãƒ¼ã‚¹é…åˆ†",
        },
        "split": {
            "metadata": {
                "activity_id": "12345",
                "date": "2025-09-22",
                "analyst": "split-section-analyst",
                "version": "1.0",
            },
            "analyses": {
                "split_1": "1kmç›®: ãƒšãƒ¼ã‚¹6'15\", å¿ƒæ‹152",
                "split_2": "2kmç›®: ãƒšãƒ¼ã‚¹6'00\", å¿ƒæ‹158",
            },
        },
        "summary": {
            "metadata": {
                "activity_id": "12345",
                "date": "2025-09-22",
                "analyst": "summary-section-analyst",
                "version": "1.0",
            },
            "summary": {
                "activity_type": {"classification": "Easy Run", "confidence": "high"},
                "overall_rating": {"score": 4.5, "stars": "â˜…â˜…â˜…â˜…â˜†"},
                "key_strengths": ["ãƒ•ã‚©ãƒ¼ãƒ åŠ¹ç‡", "ãƒšãƒ¼ã‚¹å®‰å®šæ€§"],
                "improvement_areas": ["å¿ƒæ‹ãƒ‰ãƒªãƒ•ãƒˆç®¡ç†"],
                "recommendations": "ç†æƒ³çš„ãªEasy Runãƒ†ãƒ³ãƒã‚’ç¶­æŒ",
            },
        },
    }


@pytest.mark.integration
def test_generate_report_full_workflow(
    test_db, test_activity_data, test_section_analyses, tmp_path
):
    """DuckDBã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¾ã§ã®å®Œå…¨ãªãƒ•ãƒ­ãƒ¼ã‚’ç¢ºèª."""
    import json

    import duckdb

    # Setup: Insert test data using production schema
    conn = duckdb.connect(test_db)

    # Insert activity with complete production schema
    conn.execute(
        """
        INSERT INTO activities (
            activity_id, date, activity_name, location_name,
            total_distance_km, total_time_seconds, avg_pace_seconds_per_km,
            avg_heart_rate, avg_cadence, avg_power,
            weight_kg, external_temp_c, humidity, wind_speed_ms, gear_name
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            test_activity_data["activity_date"],
            test_activity_data["activity_name"],
            "",  # location_name
            test_activity_data["distance_km"],
            test_activity_data["duration_seconds"],
            test_activity_data["avg_pace_seconds_per_km"],
            test_activity_data["avg_heart_rate"],
            test_activity_data["avg_cadence"],
            test_activity_data["avg_power"],
            70.0,  # weight_kg
            18.0,  # external_temp_c
            65,  # humidity
            2.5,  # wind_speed_ms
            "Nike Vaporfly Next% 2",  # gear_name
        ],
    )

    # Insert form efficiency data
    conn.execute(
        """
        INSERT INTO form_efficiency (
            activity_id, gct_average, gct_std, gct_rating,
            vo_average, vo_std, vo_rating,
            vr_average, vr_std, vr_rating
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            262.0,
            5.0,
            "â˜…â˜…â˜…â˜…â˜…",
            7.2,
            0.3,
            "â˜…â˜…â˜…â˜…â˜†",
            9.3,
            0.4,
            "â˜…â˜…â˜…â˜…â˜…",
        ],
    )

    # Insert performance trends data
    conn.execute(
        """
        INSERT INTO performance_trends (
            activity_id, pace_consistency, hr_drift_percentage,
            cadence_consistency, fatigue_pattern,
            warmup_avg_pace_seconds_per_km, warmup_avg_hr,
            main_avg_pace_seconds_per_km, main_avg_hr,
            finish_avg_pace_seconds_per_km, finish_avg_hr
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            0.05,
            3.5,
            "é«˜ã„å®‰å®šæ€§",
            "é©åˆ‡ãªç–²åŠ´ç®¡ç†",
            365,
            145,
            355,
            152,
            350,
            158,
        ],
    )

    # Insert HR efficiency data
    conn.execute(
        """
        INSERT INTO hr_efficiency (
            activity_id, training_type
        ) VALUES (?, ?)
    """,
        [
            test_activity_data["activity_id"],
            "aerobic_base",
        ],
    )

    # Insert section analyses
    for section_type, analysis_data in test_section_analyses.items():
        conn.execute(
            """
            INSERT INTO section_analyses (
                activity_id, activity_date, section_type, analysis_data
            ) VALUES (?, ?, ?, ?)
        """,
            [
                test_activity_data["activity_id"],
                test_activity_data["activity_date"],
                section_type,
                json.dumps(analysis_data, ensure_ascii=False),
            ],
        )

    conn.close()

    # Generate report
    worker = ReportGeneratorWorker(test_db)
    result = worker.generate_report(
        test_activity_data["activity_id"], test_activity_data["activity_date"]
    )

    # Assertions
    assert result["success"] is True
    assert result["activity_id"] == test_activity_data["activity_id"]
    assert Path(result["report_path"]).exists()

    # Verify report content
    report_content = Path(result["report_path"]).read_text(encoding="utf-8")
    assert "# ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ" in report_content
    assert "## åŸºæœ¬æƒ…å ±" in report_content
    assert "## 1. ğŸ¯ ãƒ•ã‚©ãƒ¼ãƒ åŠ¹ç‡" in report_content
    assert "## 5. âœ… ç·åˆè©•ä¾¡ã¨æ¨å¥¨äº‹é …" in report_content
    assert "Nike Vaporfly" in report_content  # Gear info


@pytest.mark.integration
def test_generate_report_partial_sections(test_db, test_activity_data, tmp_path):
    """ä¸€éƒ¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†æã®ã¿ã§ã‚‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª."""
    import json

    import duckdb

    # Setup: Insert only efficiency section
    conn = duckdb.connect(test_db)

    # Insert activity with minimal required data
    conn.execute(
        """
        INSERT INTO activities (
            activity_id, date, activity_name, location_name,
            total_distance_km, total_time_seconds, avg_pace_seconds_per_km,
            avg_heart_rate, avg_cadence, avg_power,
            weight_kg, external_temp_c, humidity, wind_speed_ms, gear_name
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            test_activity_data["activity_date"],
            test_activity_data["activity_name"],
            "",
            test_activity_data["distance_km"],
            test_activity_data["duration_seconds"],
            test_activity_data["avg_pace_seconds_per_km"],
            test_activity_data["avg_heart_rate"],
            test_activity_data["avg_cadence"],
            test_activity_data["avg_power"],
            None,  # weight_kg (optional)
            None,  # external_temp_c (optional)
            None,  # humidity (optional)
            None,  # wind_speed_ms (optional)
            None,  # gear_name (optional)
        ],
    )

    # Insert only efficiency section
    efficiency_data = {
        "metadata": {"analyst": "efficiency-section-analyst"},
        "efficiency": "GCT: 262msã®å„ªç§€ãªæ¥åœ°æ™‚é–“ã‚’ç¶­æŒã§ãã¦ã„ã¾ã™ã€‚",
    }
    conn.execute(
        """
        INSERT INTO section_analyses (
            activity_id, activity_date, section_type, analysis_data
        ) VALUES (?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            test_activity_data["activity_date"],
            "efficiency",
            json.dumps(efficiency_data, ensure_ascii=False),
        ],
    )

    conn.close()

    # Generate report
    worker = ReportGeneratorWorker(test_db)
    result = worker.generate_report(
        test_activity_data["activity_id"], test_activity_data["activity_date"]
    )

    assert result["success"] is True
    report_content = Path(result["report_path"]).read_text(encoding="utf-8")
    assert "GCT: 262ms" in report_content
    assert "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in report_content  # Missing sections


@pytest.mark.integration
def test_generate_report_activity_not_found(test_db):
    """å­˜åœ¨ã—ãªã„activity_idã§ValueErrorãŒraiseã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª."""
    worker = ReportGeneratorWorker(test_db)

    with pytest.raises(ValueError, match="No performance data found"):
        worker.generate_report(99999, "2025-09-22")


@pytest.mark.integration
def test_report_japanese_encoding(
    test_db, test_activity_data, test_section_analyses, tmp_path
):
    """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãŒæ­£ã—ãUTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª."""
    import json

    import duckdb

    # Setup
    conn = duckdb.connect(test_db)

    # Insert activity with complete data
    conn.execute(
        """
        INSERT INTO activities (
            activity_id, date, activity_name, location_name,
            total_distance_km, total_time_seconds, avg_pace_seconds_per_km,
            avg_heart_rate, avg_cadence, avg_power,
            weight_kg, external_temp_c, humidity, wind_speed_ms, gear_name
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            test_activity_data["activity_date"],
            test_activity_data["activity_name"],
            "",
            test_activity_data["distance_km"],
            test_activity_data["duration_seconds"],
            test_activity_data["avg_pace_seconds_per_km"],
            test_activity_data["avg_heart_rate"],
            test_activity_data["avg_cadence"],
            test_activity_data["avg_power"],
            70.0,  # weight_kg
            18.0,  # external_temp_c
            65,  # humidity
            2.5,  # wind_speed_ms
            "Nike Vaporfly Next% 2",  # gear_name
        ],
    )

    # Insert form efficiency data
    conn.execute(
        """
        INSERT INTO form_efficiency (
            activity_id, gct_average, gct_std, gct_rating,
            vo_average, vo_std, vo_rating,
            vr_average, vr_std, vr_rating
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            262.0,
            5.0,
            "â˜…â˜…â˜…â˜…â˜…",
            7.2,
            0.3,
            "â˜…â˜…â˜…â˜…â˜†",
            9.3,
            0.4,
            "â˜…â˜…â˜…â˜…â˜…",
        ],
    )

    # Insert performance trends data
    conn.execute(
        """
        INSERT INTO performance_trends (
            activity_id, pace_consistency, hr_drift_percentage,
            cadence_consistency, fatigue_pattern,
            warmup_avg_pace_seconds_per_km, warmup_avg_hr,
            main_avg_pace_seconds_per_km, main_avg_hr,
            finish_avg_pace_seconds_per_km, finish_avg_hr
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        [
            test_activity_data["activity_id"],
            0.05,
            3.5,
            "é«˜ã„å®‰å®šæ€§",
            "é©åˆ‡ãªç–²åŠ´ç®¡ç†",
            365,
            145,
            355,
            152,
            350,
            158,
        ],
    )

    # Insert HR efficiency data
    conn.execute(
        """
        INSERT INTO hr_efficiency (
            activity_id, training_type
        ) VALUES (?, ?)
    """,
        [
            test_activity_data["activity_id"],
            "aerobic_base",
        ],
    )

    # Insert section analyses
    for section_type, analysis_data in test_section_analyses.items():
        conn.execute(
            """
            INSERT INTO section_analyses (
                activity_id, activity_date, section_type, analysis_data
            ) VALUES (?, ?, ?, ?)
        """,
            [
                test_activity_data["activity_id"],
                test_activity_data["activity_date"],
                section_type,
                json.dumps(analysis_data, ensure_ascii=False),
            ],
        )

    conn.close()

    # Generate report
    worker = ReportGeneratorWorker(test_db)
    result = worker.generate_report(
        test_activity_data["activity_id"], test_activity_data["activity_date"]
    )

    report_content = Path(result["report_path"]).read_text(encoding="utf-8")

    # Verify Japanese text
    assert "å„ªç§€ãªæ¥åœ°æ™‚é–“" in report_content
    assert "é©åˆ‡ãªãƒšãƒ¼ã‚¹é…åˆ†" in report_content
    assert "ç†æƒ³çš„ãªç’°å¢ƒæ¡ä»¶" in report_content
